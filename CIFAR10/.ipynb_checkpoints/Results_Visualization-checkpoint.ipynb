{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualize Quality Enhancement by Showing Some Fake Images\n",
    "(1). Baseline; (2) DRS; (3) MH-GAN; (4) DRE-F-SP+RS; (5) DRE-F-SP+MH; (6) DRE-F-SP+SIR;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-2-ebb9a336bd64>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ebb9a336bd64>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    wd = '/home/xin/OneDrive/Working_directory/DDRE_Sampling_GANs/CIFAR10\"\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "wd = '/home/xin/OneDrive/Working_directory/DDRE_Sampling_GANs/CIFAR10'\n",
    "os.chdir(wd)\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.utils import save_image\n",
    "import gc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "\n",
    "from SimpleProgressBar import SimpleProgressBar\n",
    "from models import *\n",
    "from Train_DCGAN import SampDCGAN\n",
    "from Train_WGAN import SampWGAN\n",
    "from Train_MMDGAN import SampMMDGAN\n",
    "from utils import *\n",
    "\n",
    "###########################################\n",
    "#             Overall Settings\n",
    "###########################################\n",
    "GAN = \"DCGAN\" #DCGAN, WGANGP, MMDGAN\n",
    "DRE = \"DRE-F-SP\" #Candidate: None, disc, disc_MHcal, DRE-F-SP, DRE-F-uLSIF\n",
    "Sampler = \"SIR\" #Candidate: None, RS, MH, SIR\n",
    "Seed = 101\n",
    "\n",
    "###########################################\n",
    "#              GAN Settings\n",
    "###########################################\n",
    "dim_GAN = 128\n",
    "if GAN == \"DCGAN\":\n",
    "    ckpt_GAN_name = './Output/saved_models/ckpt_DCGAN_epoch_500_SEED_2019'\n",
    "elif GAN == \"WGANGP\":\n",
    "    ckpt_GAN_name = './Output/saved_models/ckpt_WGANGP_epoch_2000_SEED_2019'\n",
    "elif GAN == \"MMDGAN\":\n",
    "    ckpt_GAN_name = './Output/saved_models/ckpt_MMDGAN_epoch_4000_SEED_2019'\n",
    "    \n",
    "###########################################\n",
    "#              DRE Settings\n",
    "###########################################\n",
    "ckpt_PreCNN_name = './Output/saved_models/ckpt_PreCNNForDRE_ResNet34_epoch_200_SEED_2019_Transformation_True'\n",
    "if GAN == \"DCGAN\":\n",
    "    if DRE == \"DRE-F-SP\":\n",
    "        ckpt_DR_name = './Output/saved_models/ckpt_DRE_F_SP_MLP5_ReLU_epoch_200_SEED_2019_Lambda_0.0_DCGAN_epoch_500'\n",
    "    elif DRE == \"DRE-F-uLSIF\":\n",
    "        ckpt_DR_name = './Output/saved_models/ckpt_DRE_F_uLSIF_MLP5_ReLU_epoch_200_SEED_2019_Lambda_0.0_DCGAN_epoch_500'\n",
    "elif GAN == \"WGANGP\":\n",
    "    ckpt_DR_name = './Output/saved_models/ckpt_DRE_F_SP_MLP5_ReLU_epoch_200_SEED_2019_Lambda_0.005_WGANGP_epoch_2000'\n",
    "elif GAN == \"MMDGAN\":\n",
    "    ckpt_DR_name = './Output/saved_models/ckpt_DRE_F_SP_MLP5_ReLU_epoch_200_SEED_2019_Lambda_0.006_MMDGAN_epoch_4000'\n",
    "\n",
    "\n",
    "###########################################\n",
    "#            Sampling Settings\n",
    "###########################################\n",
    "ckpt_PreNetFIDIS_name = './Output/saved_models/ckpt_PreCNNForEvalGANs_InceptionV3_epoch_200_SEED_2019_Transformation_True'\n",
    "NFAKE = 5000\n",
    "# Sel_Class = [0,1,2,3,4,5,6,7,8,9]\n",
    "# Sel_Class = [1,7]\n",
    "NFAKE_per_class = 50\n",
    "NPOOL_SIR = 20000 #Pool size for SIR\n",
    "samp_batch_size = 1000\n",
    "pred_batch_size = 100\n",
    "MH_K = 640\n",
    "MH_mute = True #do not print sampling progress\n",
    "DR_comp_batch_size = 50\n",
    "assert samp_batch_size>DR_comp_batch_size\n",
    "assert NFAKE > NFAKE_per_class\n",
    "flag_real_imgs = False\n",
    "nrow=10\n",
    "\n",
    "###########################################\n",
    "#              Other Settings\n",
    "###########################################\n",
    "N_CLASS = 10\n",
    "NC = 3 #number of channels\n",
    "IMG_SIZE = 32\n",
    "NGPU=torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "random.seed(Seed)\n",
    "torch.manual_seed(Seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(Seed)\n",
    "\n",
    "# data loader\n",
    "means = (0.5, 0.5, 0.5)\n",
    "stds = (0.5, 0.5, 0.5)\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, stds),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "############################################\n",
    "#          fn for computing DR\n",
    "############################################\n",
    "# load pre-trained GAN\n",
    "checkpoint = torch.load(ckpt_GAN_name)\n",
    "if GAN == \"DCGAN\":\n",
    "    netG = cnn_generator(NGPU, dim_GAN).to(device)\n",
    "    netD = cnn_discriminator(True, NGPU).to(device)\n",
    "    def fn_sampleGAN(nfake, batch_size):\n",
    "        return SampDCGAN(netG, GAN_Latent_Length = dim_GAN, NFAKE = nfake, batch_size = batch_size)\n",
    "elif GAN == \"WGANGP\":\n",
    "    netG = cnn_generator(NGPU, dim_GAN).to(device)\n",
    "    netD = cnn_discriminator(True, NGPU).to(device)\n",
    "    def fn_sampleGAN(nfake, batch_size):\n",
    "        return SampWGAN(netG, GAN_Latent_Length = dim_GAN, NFAKE = nfake, batch_size = batch_size)\n",
    "elif GAN == \"MMDGAN\":\n",
    "    G_decoder = MMDGAN_Decoder(IMG_SIZE, NC, k=dim_GAN, ngf=64, ngpu=NGPU)\n",
    "    netG = MMDGAN_G(G_decoder).to(device)\n",
    "    def fn_sampleGAN(nfake, batch_size=samp_batch_size):\n",
    "        return SampMMDGAN(netG, GAN_Latent_Length = dim_GAN, NFAKE = nfake, batch_size = batch_size)\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "if GAN != \"MMDGAN\":\n",
    "    netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "\n",
    "# compute density ratios\n",
    "#--------------------------------------\n",
    "#use GAN property\n",
    "if DRE == \"disc\": \n",
    "    def comp_density_ratio(imgs):\n",
    "            #imgs: an numpy array\n",
    "            n_imgs = imgs.shape[0]\n",
    "            batch_size_tmp = DR_comp_batch_size\n",
    "            dataset_tmp = IMGs_dataset(imgs)\n",
    "            dataloader_tmp = torch.utils.data.DataLoader(dataset_tmp, batch_size=batch_size_tmp, shuffle=False, num_workers=0)\n",
    "            data_iter = iter(dataloader_tmp)\n",
    "            density_ratios = np.zeros((n_imgs+batch_size_tmp, 1))\n",
    "\n",
    "            netD.eval()\n",
    "            with torch.no_grad():\n",
    "                tmp = 0\n",
    "                while tmp < n_imgs:\n",
    "                    batch_imgs = data_iter.next()\n",
    "                    batch_imgs = batch_imgs.type(torch.float).to(device)\n",
    "                    disc_probs = netD(batch_imgs).cpu().detach().numpy()\n",
    "                    disc_probs = np.clip(disc_probs.astype(np.float), 1e-14, 1 - 1e-14)\n",
    "                    density_ratios[tmp:(tmp+batch_size_tmp)] = np.divide(disc_probs, 1-disc_probs)\n",
    "                    tmp += batch_size_tmp\n",
    "                #end while\n",
    "            return density_ratios[0:n_imgs]\n",
    "#--------------------------------------\n",
    "#use GAN property and calibration\n",
    "elif DRE == \"disc_MHcal\": \n",
    "    n_test = testset.data.shape[0]\n",
    "    batch_size_tmp = DR_comp_batch_size\n",
    "    cal_labels_fake = np.zeros((n_test,1))\n",
    "    cal_labels_real = np.ones((n_test,1))\n",
    "    cal_imgs_fake = fn_sampleGAN(nfake=n_test, batch_size=batch_size_tmp)\n",
    "    cal_imgs_real = np.transpose(testset.data, (0, 3, 1, 2))\n",
    "    #standarize real images\n",
    "    cal_imgs_real = cal_imgs_real/255.0\n",
    "    for i in range(NC):\n",
    "        cal_imgs_real[:,i,:,:] = (cal_imgs_real[:,i,:,:]-means[i])/stds[i]\n",
    "    dataset_fake = IMGs_dataset(cal_imgs_fake)\n",
    "    dataloader_fake = torch.utils.data.DataLoader(dataset_fake, batch_size=batch_size_tmp, shuffle=False, num_workers=0)\n",
    "    dataset_real = IMGs_dataset(cal_imgs_real)\n",
    "    dataloader_real = torch.utils.data.DataLoader(dataset_real, batch_size=batch_size_tmp, shuffle=False, num_workers=0)\n",
    "    del cal_imgs_fake, cal_imgs_real; gc.collect()\n",
    "\n",
    "    # get the output of disc before the final sigmoid layer; the \\tilde{D} in Eq.(4) in \"Discriminator Rejection Sampling\"\n",
    "    # def comp_disc_scores(imgs_dataloader, netD):\n",
    "    def comp_disc_scores(imgs_dataloader):\n",
    "        # imgs_dataloader: the data loader for images\n",
    "        n_imgs = len(imgs_dataloader.dataset)\n",
    "        data_iter = iter(imgs_dataloader)\n",
    "        batch_size_tmp = imgs_dataloader.batch_size\n",
    "        disc_scores = np.zeros((n_imgs+batch_size_tmp, 1))\n",
    "        netD.eval()\n",
    "        with torch.no_grad():\n",
    "            tmp = 0\n",
    "            while tmp < n_imgs:\n",
    "                batch_imgs = data_iter.next()\n",
    "                batch_imgs = batch_imgs.type(torch.float).to(device)\n",
    "                disc_probs = netD(batch_imgs).cpu().detach().numpy()\n",
    "                disc_probs = np.clip(disc_probs.astype(np.float), 1e-14, 1 - 1e-14)\n",
    "                disc_scores[tmp:(tmp+batch_size_tmp)] = np.log(np.divide(disc_probs, 1-disc_probs))\n",
    "                tmp += batch_size_tmp\n",
    "            #end while\n",
    "        return disc_scores[0:n_imgs]\n",
    "\n",
    "    # compute disc score of a given img which is in tensor format\n",
    "    # def fn_disc_score(img, netD):\n",
    "    def fn_disc_score(img):\n",
    "        #img must be a tensor: 1*NC*IMG_SIZE*IMG_SIZE\n",
    "        netD.eval()\n",
    "        with torch.no_grad():\n",
    "            img = img.type(torch.float).to(device)\n",
    "            disc_prob = netD(img).cpu().detach().numpy()\n",
    "            disc_prob = np.clip(disc_prob.astype(np.float), 1e-14, 1-1e-14)\n",
    "            return np.log(disc_prob/(1-disc_prob))\n",
    "\n",
    "    cal_disc_scores_fake = comp_disc_scores(dataloader_fake) #discriminator scores for fake images\n",
    "    cal_disc_scores_real = comp_disc_scores(dataloader_real) #discriminator scores for real images\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    X_train = np.concatenate((cal_disc_scores_fake, cal_disc_scores_real),axis=0).reshape(-1,1)\n",
    "    y_train = np.concatenate((cal_labels_fake, cal_labels_real), axis=0).reshape(-1)\n",
    "    #del cal_disc_scores_fake, cal_disc_scores_real; gc.collect()\n",
    "    cal_logReg = LogisticRegression(solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    # function for computing a bunch of images\n",
    "    # def comp_density_ratio(imgs, netD):\n",
    "    def comp_density_ratio(imgs):\n",
    "       #imgs: an numpy array\n",
    "       dataset_tmp = IMGs_dataset(imgs)\n",
    "       dataloader_tmp = torch.utils.data.DataLoader(dataset_tmp, batch_size=batch_size_tmp, shuffle=False, num_workers=0)\n",
    "       disc_scores = comp_disc_scores(dataloader_tmp)\n",
    "       disc_probs = (cal_logReg.predict_proba(disc_scores))[:,1] #second column corresponds to the real class\n",
    "       disc_probs = np.clip(disc_probs.astype(np.float), 1e-14, 1 - 1e-14)\n",
    "       density_ratios = np.divide(disc_probs, 1-disc_probs)\n",
    "       return density_ratios.reshape(-1,1)\n",
    "#--------------------------------------\n",
    "#our DRE method\n",
    "elif DRE in [\"DRE-F-SP\",\"DRE-F-uLSIF\"]: \n",
    "    # load pre-trained ResNet34\n",
    "    PreNetDRE = ResNet34(isometric_map = True, num_classes=N_CLASS, ngpu = NGPU).to(device)\n",
    "    checkpoint = torch.load(ckpt_PreCNN_name)\n",
    "    PreNetDRE.load_state_dict(checkpoint['net_state_dict'])\n",
    "    \n",
    "    # load pre-trained netDR\n",
    "    netDR = DR_MLP(\"MLP5\", ngpu=NGPU, final_ActFn=\"ReLU\").to(device)\n",
    "    checkpoint_netDR = torch.load(ckpt_DR_name)\n",
    "    netDR.load_state_dict(checkpoint_netDR['net_state_dict'])\n",
    "    \n",
    "    def comp_density_ratio(imgs):\n",
    "        #imgs: an numpy array\n",
    "        n_imgs = imgs.shape[0]\n",
    "        batch_size_tmp = DR_comp_batch_size\n",
    "        dataset_tmp = IMGs_dataset(imgs)\n",
    "        dataloader_tmp = torch.utils.data.DataLoader(dataset_tmp, batch_size=batch_size_tmp, shuffle=False, num_workers=0)\n",
    "        data_iter = iter(dataloader_tmp)\n",
    "        density_ratios = np.zeros((n_imgs+batch_size_tmp, 1))\n",
    "\n",
    "        netDR.eval()\n",
    "        PreNetDRE.eval()\n",
    "        # print(\"\\n Begin computing density ratio for images >>\")\n",
    "        with torch.no_grad():\n",
    "            tmp = 0\n",
    "            while tmp < n_imgs:\n",
    "                batch_imgs = data_iter.next()\n",
    "                batch_imgs = batch_imgs.type(torch.float).to(device)\n",
    "                _, batch_features = PreNetDRE(batch_imgs)\n",
    "                batch_weights = netDR(batch_features)\n",
    "                density_ratios[tmp:(tmp+batch_size_tmp)] = batch_weights.cpu().detach().numpy()\n",
    "                tmp += batch_size_tmp\n",
    "            #end while\n",
    "        # print(\"\\n End computing density ratio.\")\n",
    "        return density_ratios[0:n_imgs]\n",
    "    \n",
    "############################################\n",
    "#          fn for samplers\n",
    "############################################\n",
    "#---------------------------------------------\n",
    "# Rejection Sampling: \"Discriminator Rejection Sampling\"; based on https://github.com/shinseung428/DRS_Tensorflow/blob/master/config.py\n",
    "if Sampler == \"RS\":\n",
    "    def fn_enhanceSampler(nfake, batch_size=samp_batch_size):\n",
    "        ## Burn-in Stage\n",
    "        n_burnin = 50000\n",
    "        burnin_imgs = fn_sampleGAN(n_burnin, batch_size=samp_batch_size)\n",
    "        burnin_densityraios = comp_density_ratio(burnin_imgs)\n",
    "        M_bar = np.max(burnin_densityraios)\n",
    "        del burnin_imgs, burnin_densityraios; gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        ## Rejection sampling\n",
    "        enhanced_imgs = np.zeros((1, NC, IMG_SIZE, IMG_SIZE)) #initilize\n",
    "        pb = SimpleProgressBar()\n",
    "        num_imgs = 0\n",
    "        while num_imgs < nfake:\n",
    "            pb.update(float(num_imgs)*100/nfake)\n",
    "            batch_imgs = fn_sampleGAN(batch_size, batch_size)\n",
    "            batch_ratios = comp_density_ratio(batch_imgs)\n",
    "            M_bar = np.max([M_bar, np.max(batch_ratios)])\n",
    "            #threshold\n",
    "            if DRE in [\"disc\", \"disc_MHcal\"]:\n",
    "                epsilon_tmp = 1e-8;\n",
    "                D_tilde_M = np.log(M_bar)\n",
    "                batch_F = np.log(batch_ratios) - D_tilde_M - np.log(1-np.exp(np.log(batch_ratios)-D_tilde_M-epsilon_tmp))\n",
    "                gamma_tmp = np.percentile(batch_F, 80) #80 percentile of each batch; follow DRS's setting\n",
    "                batch_F_hat = batch_F - gamma_tmp\n",
    "                batch_p = 1/(1+np.exp(-batch_F_hat))\n",
    "            else:\n",
    "                batch_p = batch_ratios/M_bar\n",
    "            batch_psi = np.random.uniform(size=batch_size).reshape(-1,1)\n",
    "            indx_accept = np.where((batch_psi<=batch_p)==True)[0]\n",
    "            if len(indx_accept)>0:\n",
    "                enhanced_imgs = np.concatenate((enhanced_imgs, batch_imgs[indx_accept]))\n",
    "            num_imgs=len(enhanced_imgs)-1\n",
    "            del batch_imgs, batch_ratios; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        return enhanced_imgs[1:(nfake+1)] #remove the first all zero array\n",
    "\n",
    "#---------------------------------------------\n",
    "# MCMC, Metropolis-Hastings algorithm: MH-GAN\n",
    "elif Sampler == \"MH\":\n",
    "    trainloader_MH = torch.utils.data.DataLoader(trainset, batch_size=samp_batch_size, shuffle=True, num_workers=0)\n",
    "    def fn_enhanceSampler(nfake, batch_size=samp_batch_size):\n",
    "        enhanced_imgs = np.zeros((1, NC, IMG_SIZE, IMG_SIZE)) #initilize\n",
    "        pb = SimpleProgressBar()\n",
    "        num_imgs = 0\n",
    "        while num_imgs < nfake:\n",
    "            data_iter = iter(trainloader_MH)\n",
    "            batch_imgs_new, _ = data_iter.next()\n",
    "            batch_imgs_new = batch_imgs_new.cpu().detach().numpy()\n",
    "            batch_update_flags = np.zeros(batch_size) #if an img in a batch is updated during MH, replace corresponding entry with 1\n",
    "            for k in tqdm(range(MH_K)):\n",
    "                if not MH_mute:\n",
    "                    print((k, num_imgs))\n",
    "                batch_imgs_old = fn_sampleGAN(batch_size, batch_size)\n",
    "                batch_U = np.random.uniform(size=batch_size).reshape(-1,1)\n",
    "                batch_ratios_old = comp_density_ratio(batch_imgs_old)\n",
    "                batch_ratios_new = comp_density_ratio(batch_imgs_new)\n",
    "                batch_p = batch_ratios_old/(batch_ratios_new+1e-14)\n",
    "                batch_p[batch_p>1]=1\n",
    "                indx_accept = np.where((batch_U<=batch_p)==True)[0]\n",
    "                if len(indx_accept)>0:\n",
    "                    batch_imgs_new[indx_accept] = batch_imgs_old[indx_accept]\n",
    "                    batch_update_flags[indx_accept] = 1 #if an img in a batch is updated during MH, replace corresponding entry with 1\n",
    "            indx_updated = np.where(batch_update_flags==1)[0]\n",
    "            enhanced_imgs = np.concatenate((enhanced_imgs, batch_imgs_new[indx_updated]))\n",
    "            num_imgs=len(enhanced_imgs)-1\n",
    "            print(\"MH already got %d/%d images\" % (num_imgs,nfake))\n",
    "            del batch_imgs_new, batch_imgs_old; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        return enhanced_imgs[1:(nfake+1)] #remove the first all zero array\n",
    "\n",
    "#---------------------------------------------\n",
    "# Sampling-Importance Resampling\n",
    "elif Sampler == \"SIR\":\n",
    "   def fn_enhanceSampler(nfake, batch_size=samp_batch_size):\n",
    "       enhanced_imgs = fn_sampleGAN(NPOOL_SIR, batch_size)\n",
    "       enhanced_ratios = comp_density_ratio(enhanced_imgs)\n",
    "       weights = enhanced_ratios / np.sum(enhanced_ratios) #normlaize to [0,1]\n",
    "       resampl_indx = np.random.choice(a = np.arange(len(weights)), size = nfake, replace = True, p = weights.reshape(weights.shape[0]))\n",
    "       enhanced_imgs = enhanced_imgs[resampl_indx]\n",
    "       return enhanced_imgs\n",
    "\n",
    "\n",
    "############################################\n",
    "#          Draw fake images\n",
    "############################################\n",
    "# load pre-trained InceptionV3 (pretrained on CIFAR-10)\n",
    "PreNetFIDIS = Inception3(num_classes=10, aux_logits=True, transform_input=False)\n",
    "Filename_PreCNNForEvalGANs = './Output/saved_models/ckpt_PreCNNForEvalGANs_InceptionV3_epoch_200_SEED_2019_Transformation_True'\n",
    "checkpoint_PreNet = torch.load(Filename_PreCNNForEvalGANs)\n",
    "PreNetFIDIS = nn.DataParallel(PreNetFIDIS).to(device)\n",
    "PreNetFIDIS.load_state_dict(checkpoint_PreNet['net_state_dict'])\n",
    "\n",
    "# generate fake samples\n",
    "if DRE == \"None\" and Sampler == \"None\":\n",
    "    print(\"Directly sample from GAN >>>\")\n",
    "    fake_imgs = fn_sampleGAN(NFAKE, samp_batch_size)\n",
    "else:\n",
    "    print(\"Enhanced Sampling >>>\")\n",
    "    fake_imgs=fn_enhanceSampler(NFAKE, batch_size=samp_batch_size)\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "# classify them into 10 classes\n",
    "fake_labels = PredictLabel(fake_imgs, PreNetFIDIS, N_CLASS = N_CLASS, BATCH_SIZE = pred_batch_size, resize = (299, 299))\n",
    "fake_labels = fake_labels.astype(np.int)\n",
    "num_each_class = [len(list(group)) for key, group in groupby(np.sort(fake_labels))]\n",
    "\n",
    "\n",
    "#print(\"select NFAKE_per_class samples from each class >>>\")\n",
    "# fake_imgs_even = np.zeros((NFAKE_per_class*N_CLASS, NC, IMG_SIZE, IMG_SIZE))\n",
    "# pb = SimpleProgressBar()\n",
    "# tmp = 0\n",
    "# for i in range(N_CLASS):\n",
    "#     N_tmp = num_each_class[i] #number of fake images per class\n",
    "#     assert N_tmp > NFAKE_per_class\n",
    "#     idx_i_tmp = np.where(fake_labels==i)[0]\n",
    "#     np.random.shuffle(idx_i_tmp)\n",
    "#     idx_i_tmp = idx_i_tmp[0:NFAKE_per_class]\n",
    "#     fake_imgs_even[tmp:(tmp+NFAKE_per_class)] = fake_imgs[idx_i_tmp]\n",
    "#     tmp += NFAKE_per_class\n",
    "#     pb.update(float(tmp)*100/(NFAKE_per_class*N_CLASS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select NFAKE_per_class samples from each class >>>\n",
      "100% [##################################################]\n"
     ]
    }
   ],
   "source": [
    "# select NFAKE_per_class samples from each class\n",
    "NFAKE_per_class = 10\n",
    "Sel_Class = [0,1,2,3,4,5,6,7,8,9]\n",
    "# Sel_Class = [1,7]\n",
    "print(\"select NFAKE_per_class samples from each class >>>\")\n",
    "fake_imgs_even = np.zeros((NFAKE_per_class*len(Sel_Class), NC, IMG_SIZE, IMG_SIZE))\n",
    "pb = SimpleProgressBar()\n",
    "tmp = 0\n",
    "for i in range(len(Sel_Class)):\n",
    "    N_tmp = num_each_class[Sel_Class[i]] #number of fake images per class\n",
    "    assert N_tmp > NFAKE_per_class\n",
    "    idx_i_tmp = np.where(fake_labels==Sel_Class[i])[0]\n",
    "    np.random.shuffle(idx_i_tmp)\n",
    "    idx_i_tmp = idx_i_tmp[0:NFAKE_per_class]\n",
    "    fake_imgs_even[tmp:(tmp+NFAKE_per_class)] = fake_imgs[idx_i_tmp]\n",
    "    tmp += NFAKE_per_class\n",
    "    pb.update(float(tmp)*100/(NFAKE_per_class*len(Sel_Class))) \n",
    "\n",
    "#save selected fake images\n",
    "image_filename = './Output/saved_images/Visualize_Quality_Improvement_GAN_'\\\n",
    "                +GAN+'_DRE_'+DRE+'_Sampler_'+Sampler+'.pdf'\n",
    "save_image(torch.from_numpy(fake_imgs_even).data, image_filename, nrow=nrow, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find closest real imgs; using mean square error\n",
    "#if the closest real images are very similar to their counterpart, we may have overfitting problems here.\n",
    "print(\"Find closest real images for fake images >>>\")\n",
    "IMGSr_train = np.transpose(trainset.data, (0, 3, 1, 2))\n",
    "IMGSr_train = IMGSr_train/255.0\n",
    "for i in range(3):\n",
    "    IMGSr_train[:,i,:,:] = (IMGSr_train[:,i,:,:] - 0.5) / 0.5\n",
    "closest_real_imgs_for_fake = np.zeros((fake_imgs_even.shape[0], NC, IMG_SIZE, IMG_SIZE))    \n",
    "mse_fake_to_real = np.zeros((fake_imgs_even.shape[0], IMGSr_train.shape[0]))\n",
    "for i in tqdm(range(fake_imgs_even.shape[0])):\n",
    "    for j in range(IMGSr_train.shape[0]):\n",
    "        mse_fake_to_real[i,j] = np.mean((fake_imgs_even[i]-IMGSr_train[j])**2)\n",
    "    indx_min = np.argmin(mse_fake_to_real[i,:])\n",
    "    closest_real_imgs_for_fake[i] = IMGSr_train[indx_min]\n",
    "\n",
    "#save closest real images\n",
    "image_filename = './Output/saved_images/Visualize_Quality_Improvement_GAN_'\\\n",
    "                +GAN+'_DRE_'+DRE+'_Sampler_'+Sampler+'_ClosestRealImgs.pdf'\n",
    "save_image(torch.from_numpy(closest_real_imgs_for_fake).data, image_filename, nrow=nrow, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFAKE_per_class = 10\n",
    "# Sel_Class = [0,1,2,3,4,5,6,7,8,9]\n",
    "# # Sel_Class = [1,7]\n",
    "\n",
    "#if flag_real_imgs: #output real images\n",
    "real_imgs_test = np.transpose(testset.data, (0, 3, 1, 2))\n",
    "#rescale to [0,1]\n",
    "real_imgs_test = real_imgs_test/255.0\n",
    "#rescale to [-1,1]\n",
    "for i in range(3):\n",
    "   real_imgs_test[:,i,:,:] = (real_imgs_test[:,i,:,:] - 0.5) / 0.5\n",
    "real_labels_test = np.array(testset.targets)\n",
    "\n",
    "# select NFAKE_per_class real samples from each class\n",
    "print(\"select NFAKE_per_class real samples from each class >>>\")\n",
    "real_imgs_even = np.zeros((NFAKE_per_class*len(Sel_Class), NC, IMG_SIZE, IMG_SIZE))\n",
    "pb = SimpleProgressBar()\n",
    "tmp = 0\n",
    "for i in range(len(Sel_Class)):\n",
    "    idx_i_tmp = np.where(real_labels_test==Sel_Class[i])[0]\n",
    "    np.random.shuffle(idx_i_tmp)\n",
    "    idx_i_tmp = idx_i_tmp[0:NFAKE_per_class]\n",
    "    real_imgs_even[tmp:(tmp+NFAKE_per_class)] = real_imgs_test[idx_i_tmp]\n",
    "    tmp += NFAKE_per_class\n",
    "    pb.update(float(tmp)*100/(NFAKE_per_class*len(Sel_Class)))\n",
    "\n",
    "#save images\n",
    "image_filename = './Output/saved_images/Visualize_Quality_Improvement_GAN_'\\\n",
    "                +GAN+'_real_data.pdf'\n",
    "save_image(torch.from_numpy(real_imgs_even).data, image_filename, nrow=nrow, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compare convergence of uLSIF and SP loss with DCGAN samples\n",
    "Fix DR model (MLP5 and ReLU) and Sampler (RS) <br/>\n",
    "Plot training losses under lambda's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "wd = \"/home/xin/Working directory/DDRE_Sampling_GANs/CIFAR10/Output/Training_loss_fig/Compare_convergence_diff_loss\"\n",
    "os.chdir(wd)\n",
    "# name of npy files; under the optimal setting\n",
    "\n",
    "file_uLSIF_1 = wd+\"/DRE_F_uLSIF_MLP5_LAMBDA0.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_uLSIF_2 = wd+\"/DRE_F_uLSIF_MLP5_LAMBDA0.1_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_uLSIF_3 = wd+\"/DRE_F_uLSIF_MLP5_LAMBDA1.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_uLSIF_4 = wd+\"/DRE_F_uLSIF_MLP5_LAMBDA5.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_uLSIF_5 = wd+\"/DRE_F_uLSIF_MLP5_LAMBDA10.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "\n",
    "file_SP_1 = wd+\"/DRE_F_SP_MLP5_LAMBDA0.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_SP_2 = wd+\"/DRE_F_SP_MLP5_LAMBDA0.1_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_SP_3 = wd+\"/DRE_F_SP_MLP5_LAMBDA1.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_SP_4 = wd+\"/DRE_F_SP_MLP5_LAMBDA5.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "file_SP_5 = wd+\"/DRE_F_SP_MLP5_LAMBDA10.0_epochDRE500_DCGAN_epochGAN500_TrainLoss.npy\"\n",
    "\n",
    "# load training loss\n",
    "loss_uLSIF_1 = np.load(file_uLSIF_1)\n",
    "loss_uLSIF_2 = np.load(file_uLSIF_2)\n",
    "loss_uLSIF_3 = np.load(file_uLSIF_3)\n",
    "loss_uLSIF_4 = np.load(file_uLSIF_4)\n",
    "loss_uLSIF_5 = np.load(file_uLSIF_5)\n",
    "loss_SP_1 = np.load(file_SP_1)\n",
    "loss_SP_2 = np.load(file_SP_2)\n",
    "loss_SP_3 = np.load(file_SP_3)\n",
    "loss_SP_4 = np.load(file_SP_4)\n",
    "loss_SP_5 = np.load(file_SP_5)\n",
    "\n",
    "\n",
    "# plot training curves\n",
    "filename_uLISF = wd+\"/Convergence_uLISF.pdf\"\n",
    "filename_SP = wd+\"/Convergence_SP.pdf\"\n",
    "num_epochs = 500\n",
    "x = np.arange(start = 1, stop = num_epochs+1)\n",
    "\n",
    "f1 = plt.figure()\n",
    "#f1.set_size_inches(10, 8)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(x, loss_uLSIF_1, c='r', label = r\"$\\lambda=0$\")\n",
    "plt.plot(x, loss_uLSIF_2, c='b', label = r\"$\\lambda=0.1$\")\n",
    "plt.plot(x, loss_uLSIF_3, c='y', label = r\"$\\lambda=1$\")\n",
    "plt.plot(x, loss_uLSIF_4, c='g', label = r\"$\\lambda=5$\")\n",
    "plt.plot(x, loss_uLSIF_5, c='m', label = r\"$\\lambda=10$\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "f1.savefig(filename_uLISF, bbox_inches='tight')\n",
    "\n",
    "f2 = plt.figure()\n",
    "#f2.set_size_inches(10, 8)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(x, loss_SP_1, c='r', label = r\"$\\lambda=0$\")\n",
    "plt.plot(x, loss_SP_2, c='b', label = r\"$\\lambda=0.1$\")\n",
    "plt.plot(x, loss_SP_3, c='y', label = r\"$\\lambda=1$\")\n",
    "plt.plot(x, loss_SP_4, c='g', label = r\"$\\lambda=5$\")\n",
    "plt.plot(x, loss_SP_5, c='m', label = r\"$\\lambda=10$\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "f2.savefig(filename_SP, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualize the IS or FID under different lambdaâ€™s for DRE-F-SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
